{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40ae4298-a3d0-4412-8075-37e573674e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5121f27e-4f1b-42d8-95da-2f3fe6654818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation du dataset\n",
    "diabete_data = pd.read_csv('../../datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d09e6859-59fc-415c-aac8-d8e8f0af49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabete_data.loc[(diabete_data[\"Insulin\"].isnull()) | (diabete_data[\"SkinThickness\"].isnull()) | (diabete_data[\"BMI\"].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed9e7de1-536a-4d27-875a-28e944aab998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on compte le nombre de valeur manquante pour chaque colonne\n",
    "# diabete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45cbb77c-b748-4c68-82ba-03bb88e2cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretraitement du datatset: on va remplacer les valeurs 0 par la moyenne des valeurs de leur champ\n",
    "for column in diabete_data.iloc[:, 0:6]:\n",
    "    diabete_data[column] = diabete_data[column].replace(0, np.nan)\n",
    "    mean = diabete_data[column].mean(skipna=True)\n",
    "    diabete_data[column] = diabete_data[column].replace(np.nan, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cac60ecc-f7b6-4c03-b859-2f6a2096e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation de nos données d'entrée (X) et de nos données cible (Y)\n",
    "X = diabete_data.iloc[:, 0:8]\n",
    "Y = diabete_data.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03935e44-a854-4336-a1cc-8c96600a0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# division du dataset en des données d'entrainement et de test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8fd15a6-00a4-408a-9eaf-264834dade89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9369389448423614"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = x_train[\"Glucose\"].std()\n",
    "mean = x_train[\"Glucose\"].mean()\n",
    "x = x_train[\"Glucose\"].values[0]\n",
    "z = (x-mean)/std\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c90e09b-944b-4750-8beb-3ce15acd39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # on va standardiser ie normaliser nos données\n",
    "# sc_X = StandardScaler()\n",
    "# x_train = sc_X.fit_transform(x_train) # il ne faut pas oublier d'ajouter le fit_ car on manipule des données d'entrainement, sinon il y'aura une erreur\n",
    "# x_test = sc_X.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3fe48d0-efbf-4181-abc7-b59356dd7189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.198684153570664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determination de la valeur optimal de k\n",
    "# Methode 1:\n",
    "# --Etape1: on calcule la racine carré de la taille total de notre data point (y_test)\n",
    "# --Etape2: en fonction de la valeur obtenue à l'etape1, on choisie une valeur impaire de k (tu peux te referer au chiffre après la virgule pour voir si tu dois choisir la valeur impaire superieur ou la valeur impaire inferieur)\n",
    "# pour  eviter toute confusion entre 2 classe de données par ce que qu'avec une valeur impaire on est sûr que 2 classes de données n'auront jamais le même nombre de point de données. \n",
    "sqrt(len(y_test))\n",
    "# donc ici la valeur optimal de k est 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1bb1e23b-611d-457c-a946-b37c95d72382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.851024208566108"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, p=2, metric='euclidean') # p: c'est l'hyper paramètre qui definit la metric qu'on veut utiliser. Si c'est 1 c'est Manhattan, si c'est 2 c'est Euclidienne.\n",
    "knn.fit(x_train, y_train)\n",
    "knn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a40c4dd-255f-43ef-bbcf-a7e8d2312770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7316017316017316"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35de02be-1f6e-4c44-bf59-2a4b3f274d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_predict = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89349404-8585-4a2b-bec4-3db35945a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,  21],\n",
       "       [ 37,  37]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45eaceda-9b1e-4e39-8ca1-9be40400c94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5866666666666667"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56f01656-6f63-4ca6-8d2a-76289df54dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7316017316017316"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "43d7ecce-f073-4456-8fa6-9d37a18a687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01272801, -0.50751191,  0.24930428, -0.02059486, -0.02680539,\n",
       "        1.79998848,  0.6425647 , -0.80638406])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on va standardiser ie normaliser nos données\n",
    "sc_X = StandardScaler()\n",
    "x_train = sc_X.fit_transform(x_train) # il ne faut pas oublier d'ajouter le fit_ car on manipule des données d'entrainement, sinon il y'aura une erreur\n",
    "x_test = sc_X.transform(x_test)\n",
    "x_train[19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
